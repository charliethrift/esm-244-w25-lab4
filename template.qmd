---
title: "Lab 4"
author: "Charlie Thrift"
format: 
  html: 
    embed-resources: true
    code-fold: show
    toc: true
execute:
  eval: true
  message: false
  warning: false
---


```{r setup}

library(tidyverse)
library(here)
library(ggfortify) # For PCA biplot

```

# Principal components analysis (PCA)

Principal components analysis is an ordination method allowing us to glean as much about our multivariate data as possible in a simplified number of dimensions.

Here, we'll use [data from the Human Development Index](https://hdr.undp.org/data-center).  Quick overview of the HDI:

> The Human Development Index (HDI) is a summary measure of average achievement in key dimensions of human development: a long and healthy life, being knowledgeable and having a decent standard of living. The HDI is the geometric mean of normalized indices for each of the three dimensions.

> The health dimension is assessed by life expectancy at birth, the education dimension is measured by mean of years of schooling for adults aged 25 years and more and expected years of schooling for children of school entering age. The standard of living dimension is measured by gross national income per capita. The HDI uses the logarithm of income, to reflect the diminishing importance of income with increasing GNI. The scores for the three HDI dimension indices are then aggregated into a composite index using geometric mean. Refer to Technical notes for more details.


Load in the data using `read_csv`. Perform some exploratory analysis on the data to get a better grasp of the structure. What do we need for pca to work? What variable needs to be transformed according to the information presented above?


```{r}
hdi_data <- read_csv("data/hdi_clean.csv")

# exploration
# PCA uses numerical data, so we should change our "hdicode" column from ranges to numbers
## values are Low, Medium, High, and Very High
hdi_data$hdicode_numeric <- NA
hdi_data$hdicode_numeric[hdi_data$hdicode == "Low"]<- 1
hdi_data$hdicode_numeric[hdi_data$hdicode == "Medium"]<- 2
hdi_data$hdicode_numeric[hdi_data$hdicode == "High"]<- 3
hdi_data$hdicode_numeric[hdi_data$hdicode == "Very High"]<- 4

ggplot(hdi_data, aes(lat,mf_2021))+
  geom_point(aes(color=hdicode))


hdi_dat_long<-hdi_data %>% 
  pivot_longer(names_to = "name",values_to = "value",where(is.numeric))

ggplot(hdi_dat_long,aes(value))+
  geom_histogram()+
  facet_wrap(~name,scales="free_x")

hdi_data <- hdi_data %>% 
  drop_na() %>% 
  mutate(gnipc_2021=log(gnipc_2021)) %>% 
  mutate(hdicode=factor(hdicode, levels=c("Low","Medium","High","Very High")))
```



Run the pca using the `prcomp` function. What extra argument do we need to include? Make sure to select only the numeric columns for the pca

```{r}
hdi_pca <- hdi_data %>% 
  select(where(is.numeric)) %>%
  prcomp(scale=T)

summary(hdi_pca)
```


Examine the structure of the hdi_pca object. What do you think each piece means? Use documentation to help you understand the output.



``` {r}
# See the loadings (weighting for each principal component)
hdi_pca$rotation
```

What can we say about the contributions of these variables to PC1, PC2, and PC3?
*Using summary(), we see that PC1 has 71.5% of the variation, and with PC2 we explain 81.1% of the variation. Looks like we should only keeo 2 Principal Components.*

## Scree Plots

Let's make the screeplot by hand. First, what is the variable of interest on the y-axis and x-axis in a screeplot? How do we extract this information from the PCA object?

Create a dataframe with the necessary indgreidents to make a screeplot. One piece that may not be immediately obvious is provided to get you started. We'll need to keep track of which PC is which, `colnames(hdi_pca$rotation)` will give you the order of the PCs.

```{r}
pc_names <- colnames(hdi_pca$rotation)

variation <- c(0.7145, 0.0960, 0.07869, 0.03699, 
               0.0286, 0.01838, 0.01137, 0.00884, 0.00659) #copied from summary above
var <- ((hdi_pca$sdev)^2)/(sum((hdi_pca$sdev)^2)) # calculate the squared value of the standard deviation, then divde by the sum of all of those variances
total <- (hdi_pca$sdev)^2

# Use this data frame to make the screeplot
pct_expl_df <- data.frame(pc=pc_names,
                          variation=var,
                          total = total
                          
  
  
)

# Screeplot
ggplot(pct_expl_df, aes(pc,variation))+
  geom_col(fill="cornflowerblue")+
  theme_minimal()+
  scale_y_continuous(labels=scales::percent,expand=c(0,0))+
  labs(x="Principal Component",y="Variance Explained")
```


We can use ggfortify to create a screeplot as well.  This is a bit more automated, but less flexible. Great for diagnostics, but not for publication.

```{r}
# Variance explained by each PC
screeplot(hdi_pca, type = "lines")
screeplot(hdi_pca, type = "barplot")
```

## ggfortify autoplots

Autoplot can take a PCA object the original dataframe, and plot the observations in the new PC space.  It can also plot the loadings of the variables. Run the code chunk first to see the biplot of HDI data.

One cool feature of ggfortify plots is that they follow the same graphics grammar after the initial plot is created.  So you can add layers, change themes, etc. Clean up the biplot to make it more presentable. (Hint: use the data)


``` {r}

autoplot(hdi_pca,
     	data = hdi_data,
     	loadings = TRUE,
     	colour = 'hdicode',
     	loadings.label = TRUE,
     	loadings.colour = "black",
     	loadings.label.colour = "black",
     	loadings.label.vjust = -0.5
     	) +
  scale_color_manual(values = c('red', 'orange', 'yellowgreen', 'darkgreen')) +
  theme_minimal()

# It's not perfect, but it's enough for now...
```


Complete the postlab exercise on your own. The data is stored in the data folder called `grazing_env.csv`.  The data is from a study on the effects of grazing on soil properties.  





Github copilot is a tool that uses AI to help you write code.  It's not perfect, but it can be helpful.  You can install it as an extension in VSCode.  It's not perfect, but it can be helpful.  Here's an example of how it can help you write code.  The code below is not perfect, but it's a good start.  You can use it to help you write the code for the postlab.

